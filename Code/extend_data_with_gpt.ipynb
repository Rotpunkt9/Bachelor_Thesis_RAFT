{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import tiktoken\n",
    "#from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from tqdm import tqdm\n",
    "# Open AI API Key\n",
    "openai.api_key = \"YOUR_SECRET_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "#function for API request\n",
    "# we want the model to return a JSON object\n",
    "def get_completion_from_messages(messages,\n",
    "                                 model=\"gpt-3.5-turbo\",\n",
    "                                 temperature=0.7,\n",
    "                                 max_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    return json.loads(response.choices[0].message[\"content\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "#function to count the number of tokens\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "def count_tokens(text) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    num_tokens = len(encoding.encode(text))\n",
    "    return num_tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# create a rationale given a news article\n",
    "def get_rationale(article):\n",
    "    impersonator = \"You are an expert AI fact checker trained to detect fake news.\"\n",
    "    instructor = \"Is this article real or fake news? Analyze the given text in detail as a fact checker would. Explain your reasoning step-by-step. Check for misleading information, false claims, biased language. If the news article is real, respond with 1 for 'True', if fake, respond with 0 for 'False'.\"\n",
    "    cloze_prompt = \"Structure your answer as a JSON object with the two keys 'rationale' for your analytic reasoning and 'prediction' for your final prediction. The values for 'prediction' are binary. Either 1 for a real article or 0 for fake news. In 'rationale' you provide a string with your detailed reasoning process that led you to the decision you took. Remember if the article contains misleading information, false claims, biased language or any other hints of disinformation your prediction should be 0 for fake news, else 1 for true news. To summarize the JSON object looks like this: {'rationale': <your_analytic_reasoning_process>, 'prediction': <your_prediction[0,1]>} \"\n",
    "    prompt = f\"{instructor} {cloze_prompt}\"\n",
    "    system_message = impersonator\n",
    "    user_message = prompt +\"Here is the article for you to analyze: \"+ article\n",
    "\n",
    "    messages =  [\n",
    "        {'role':'system',\n",
    "         'content': system_message},\n",
    "        {'role':'user',\n",
    "         'content': user_message},\n",
    "    ]\n",
    "    input = user_message + system_message\n",
    "    input_tokens = count_tokens(input)\n",
    "    response = get_completion_from_messages(messages)\n",
    "    #print(response)\n",
    "    model_prediction = response.get(\"prediction\")\n",
    "    rationale = response.get('rationale')\n",
    "    return model_prediction, rationale, input_tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rationale': 'The given text does not present any clear indicators of fake news. It discusses a real initiative by Rob Corddry, a known comedian, to pay tribute to medical workers treating COVID-19. The information provided seems plausible and there are no obvious false claims or misleading information in the text.', 'prediction': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": "(1,\n 'The given text does not present any clear indicators of fake news. It discusses a real initiative by Rob Corddry, a known comedian, to pay tribute to medical workers treating COVID-19. The information provided seems plausible and there are no obvious false claims or misleading information in the text.',\n 344)"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "get_rationale()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def extend_data(dataframe, filename, max_retries=5):\n",
    "    \"\"\"\n",
    "    :param dataframe: the dataset you want the model to create rationales for\n",
    "    IMPORTANT: thsi dataframe needs to have a column called \"text\" which contains the news articles\n",
    "    :param filename: the path and filename to save you csv file\n",
    "    :param max_retries: how often you want to retry the API request in case something went wrong\n",
    "    \"\"\"\n",
    "    model_predictions = []\n",
    "    rationales = []\n",
    "    input_tokens = []\n",
    "    for i in tqdm(range(len(dataframe))):\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                prediction, rationale, tokens = get_rationale(dataframe.text[i])\n",
    "                model_predictions.append(prediction)\n",
    "                rationales.append(rationale)\n",
    "                input_tokens.append(tokens)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}. Attempt {attempt+1} of {max_retries}. Retrying...\")\n",
    "        else:\n",
    "            print(f\"Max retries exceeded for index {i}. Request failed.\")\n",
    "            model_predictions.append(\"Error\")\n",
    "            rationales.append(\"Error\")\n",
    "            input_tokens.append(\"Error\")\n",
    "\n",
    "\n",
    "    extended_dataframe = dataframe.assign(model_prediction = model_predictions, rationale = rationales, tokens_for_request = input_tokens)\n",
    "    # Save the DataFrame as a CSV file\n",
    "    extended_dataframe.to_csv(filename, index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
